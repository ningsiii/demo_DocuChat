import streamlit as st
from demos.ai_hub.ingest    import ingest_pdf
from demos.ai_hub.summary import build_summary_chain, human_messages
from demos.ai_hub.chat  import qa_agent
from langchain.chains import LLMChain
from demos.ai_hub.text_utils import postprocess_docs
from demos.ai_hub.vector_store import build_vector_store, top_k_context
from langchain.memory import ConversationBufferMemory
from langchain.schema import HumanMessage, AIMessage

# 0.ä¼šè¯çŠ¶æ€
for key in ("docs","insights","outlines","report","chat_history","metrics"):
    if key not in st.session_state:
        if key=="metrics":
            st.session_state[key]={}
        elif key=="report":
            st.session_state[key]=""
        else:
            st.session_state[key]=[]

# 1. ä¾§è¾¹æ 
st.sidebar.title("ğŸ”§ é…ç½® & ç›‘æ§")
# 1.1 APIkey+Provider
with st.sidebar:
    api_key=st.text_input("ğŸ”‘è¯·è¾“å…¥APIå¯†é’¥",type="password")
    #provider=st.selectable("åµŒå…¥æœåŠ¡å•†",["OpenAI","é€šä¹‰åƒé—®","DeepSeek"],index=None)
    provider_display = {
        "OpenAI": "openai",
        "é€šä¹‰åƒé—®": "dashscope",
        "DeepSeek": "deepseek",
    }
    provider_name = st.selectbox(
        "åµŒå…¥æœåŠ¡å•†",
        options=list(provider_display.keys()),
        index=None
    )
    provider = provider_display.get(provider_name)
# 1.2 ç›‘æ§ï¼ˆæŠ˜å ï¼‰
with st.sidebar.expander("ğŸ“Š ç›‘æ§",expanded=False):
    m=st.session_state.metrics
    st.metric("ç´¢å¼• Tokens",     m.get("ingest",  0))
    st.metric("æ‘˜è¦ Tokens",     m.get("research",0))
    st.metric("å¯¹è¯ Tokens",     m.get("chat",    0))
    st.markdown(f"**æ€»è®¡**ï¼š{sum(m.values())}Tokens")
st.sidebar.header("â„¹ï¸ ä½¿ç”¨å°è´´å£« & æŠ€èƒ½äº®ç‚¹")
st.sidebar.markdown(
    """
    æ¬¢è¿ä½“éªŒæœ¬ Demoï¼  
    - **ä¸Šä¼  PDF**ï¼Œä¸€é”®æå–å…³é”®ä¿¡æ¯å¹¶ç”Ÿæˆä¸­æ–‡æ‘˜è¦ï¼ˆæ”¯æŒå¤–æ–‡æ–‡æ¡£ï¼‰  
    - **æ£€ç´¢å¢å¼ºå¯¹è¯**ï¼Œç”¨ä¸­æ–‡ä¸æ–‡æ¡£å†…å®¹è‡ªç”±äº¤æµï¼ˆæ”¯æŒå†å²æ¶ˆæ¯æŸ¥çœ‹ï¼‰

    æŠ€æœ¯æ ˆï¼šFAISS å‘é‡æ£€ç´¢ â€¢ LangChain RAG â€¢ å¤§æ¨¡å‹é›†æˆ â€¢ Streamlit å¿«é€Ÿéƒ¨ç½²  
    """
)
"## å‘é‡æ£€ç´¢+LLMï¼šæ™ºèƒ½æ‘˜è¦ä¸å¯¹è¯é—®ç­”"


#2 æ•°æ®é‡‡é›†
"##### æ•°æ®é‡‡é›†"
with st.expander("# è¯·ä¸Šä¼ éœ€è¦è¯»å–çš„æ–‡æ¡£ï¼Œæ–‡æ¡£è¯­è¨€ä¸é™",expanded=True):
    col_input,col_upload=st.columns([3,1])
    uploaded_file = st.file_uploader("ä¸Šä¼  PDF", type="pdf", key="upload")
    prepare=st.button("å‡†å¤‡æ•°æ®")
    if prepare is True:
        if not uploaded_file:
            st.warning("è¯·ä¸Šä¼ æ–‡ä»¶")
            st.stop()
        if not provider or not api_key:
            st.warning("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥API KEYå¹¶é€‰æ‹©æœåŠ¡å•†")
            st.stop()
    #2.2:å¸ƒå±€â€”â€”æœç´¢è¾“å…¥ã€æœç´¢æŒ‰é’®ã€æ–‡ä»¶ä¸Šä¼ 
        with st.spinner("æ•°æ®è¯»å–ä¸­ï¼Œè¯·ç¨ç­‰â€¦â€¦"):
            docs = []
            if uploaded_file:
                pdf_chunks = ingest_pdf(
                    file_or_buffer=uploaded_file,
                    api_key=api_key,
                    provider=provider,
                )
                docs += [{"content": c, "source": "pdf"} for c in pdf_chunks]
                st.write("PDF å·²å»ºç´¢å¼•")
            docs_clean=postprocess_docs(docs,min_len=80)
            st.session_state.docs=docs_clean
            vec_store=build_vector_store(
                docs_clean,provider=provider,api_key=api_key
            )
            st.session_state.vec_store=vec_store
            st.session_state.docs_json = None
            st.success(f"å·²å‡†å¤‡å¥½{len(docs_clean)}æ¡æ–‡æ¡£ç‰‡æ®µ")
if st.session_state.get("docs"):
    with st.expander("ğŸ“„ æŸ¥çœ‹å·²å‡†å¤‡å¥½çš„æ–‡æ¡£ç‰‡æ®µ", expanded=False):
         for item in st.session_state.docs:
            st.markdown(f"[{item['source'].upper()}] {item['content']}")
st.divider()
"##### åŠŸèƒ½æ¿å—"
#3.2 ä¸»é¢æ¿
tab1,tab2=st.tabs(["âœï¸æ™ºèƒ½æ‘˜è¦","ğŸ’¬æ–‡æ¡£æ™ºèƒ½é—®ç­”"])
with tab1:
    docs = st.session_state.get("docs", [])
    if not docs:
        st.info("è¯·å…ˆåœ¨ã€å‡†å¤‡æ•°æ®ä¸­ã€å®Œæˆå‡†å¤‡")
        st.stop()
    # ----æ‘˜è¦----
    num_points=st.slider(
        label="è¯·é€‰æ‹©è¦ç‚¹æ•°é‡",
        min_value=1,
        max_value=10,
        value=5
    )
    if st.button("ç”Ÿæˆæ™ºèƒ½æ‘˜è¦"):
        with st.spinner("æ•°æ®è¯»å–ä¸­ï¼Œè¯·ç¨ç­‰â€¦â€¦"):
            chain=build_summary_chain(provider,api_key)
            full_text="\n\n".join([d["content"]for d in docs])
            summary=chain.run(num_points=num_points,context=full_text)
            st.markdown(summary)
            st.session_state["summary"]=summary
    if "summary" in st.session_state:
        st.subheader("ğŸ“‘ æ‘˜è¦ç»“æœ")
        st.markdown(st.session_state["summary"])
    else:
        st.info("æ‘˜è¦å°šæœªç”Ÿæˆï¼Œç‚¹å‡»ä¸Šæ–¹æŒ‰é’®è¯•è¯•ã€‚")
with tab2:
    if "memory"not in st.session_state:
        st.session_state["memory"]=ConversationBufferMemory(
            return_messages=True,
            memory_key="chat_history",
        )
    question=st.text_input("å¯¹æ–‡ä»¶å†…å®¹è¿›è¡Œæé—®",disabled=not uploaded_file)
    if st.button("æé—®"):
        if not docs:
            st.warning("è¯·å…ˆå‡†å¤‡å¥½æ–‡æ¡£")
        elif not question:
            st.warning("è¯·è¾“å…¥é—®é¢˜å†…å®¹")
        else:
            with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰â€¦â€¦"):
                contexts=[d["content"]for d in docs]
                response = qa_agent(
                provider = provider,
                api_key = api_key,
                contexts = contexts,
                question = question,
                memory=st.session_state["memory"]
                )
               # æå–å¹¶å±•ç¤ºå›ç­”
                st.session_state["memory"] = response["memory"]
                answer = response["answer"]
                st.write("### å›ç­”")
                st.write(answer)
    if st.session_state["memory"].chat_memory.messages:
        history = st.session_state["memory"].chat_memory.messages
        if history:
            with st.expander("å†å²æ¶ˆæ¯"):
                for msg in history:
                    if isinstance(msg, HumanMessage):
                        st.markdown(f"**ä½ **ï¼š{msg.content}")
                    elif isinstance(msg, AIMessage):
                        st.markdown(f"**AI**ï¼š{msg.content}")
                    else:
                        # å…¶å®ƒç±»å‹ï¼ˆå¦‚ SystemMessageï¼‰ä¹Ÿä¸€å¹¶æ˜¾ç¤º
                        st.markdown(f"**{msg.__class__.__name__}**ï¼š{msg.content}")

















